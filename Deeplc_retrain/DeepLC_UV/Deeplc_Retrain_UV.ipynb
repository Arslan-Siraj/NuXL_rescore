{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 20:28:34.287048: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-11 20:28:35.078952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-11 20:28:38.811050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-11 20:28:38.817083: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from deeplcretrainer import deeplcretrainer\n",
    "import pandas as pd\n",
    "from tensorflow.python.eager import context\n",
    "from deeplc import DeepLC\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "from deeplc.feat_extractor import FeatExtractor\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = FeatExtractor(\"/home/ubuntu/NuXL_rescore/unimod/unimod_to_formula.csv\")\n",
    "df_train_file = \"/home/ubuntu/NuXL_rescore/Deeplc_retrain/Train_RNA_UV.csv\"\n",
    "base_model = \"/home/ubuntu/Rescoring/RT_deeplc_model/base_model/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training \n",
    "\n",
    "_ = tf.Variable([1])\n",
    "context._context = None\n",
    "context._create_context()\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1) \n",
    "\n",
    "models = deeplcretrainer.retrain(\n",
    "    [df_train_file],\n",
    "    mods_transfer_learning=[\n",
    "        base_model +\"/full_hc_train_1fd8363d9af9dcad3be7553c39396960.hdf5\",\n",
    "        base_model +\"/full_hc_train_8c22d89667368f2f02ad996469ba157e.hdf5\",\n",
    "        base_model +\"/full_hc_train_cb975cfdd4105f97efa0b3afffe075cc.hdf5\"\n",
    "    ],\n",
    "    freeze_layers=True,\n",
    "    n_epochs=40,\n",
    "    costum_modification_file = \"/home/ubuntu/NuXL_rescore/unimod/unimod_to_formula.csv\",\n",
    "    freeze_after_concat=0,\n",
    "    plot_results= True,\n",
    "    write_csv_results = True,\n",
    "    regularizer_val=[0.000025]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_linear_regression_plot_(df:pd.DataFrame, x=\"tr\", y=\"predicted_rt\", name=\"evaluate_regression\", model_name = \"base model\"):\n",
    "    ci=95\n",
    "    n_sample=10000000\n",
    "    if len(df) > n_sample:\n",
    "        df = df.sample(n_sample, replace=False)\n",
    "    gls = sm.GLS(df[y], sm.add_constant(df[x]))\n",
    "    res = gls.fit()\n",
    "    summary = res.summary(alpha=1-ci/100.0)\n",
    "    dfs = []\n",
    "    results_as_html = summary.tables[0].as_html()\n",
    "    dfs.append(pd.read_html(results_as_html, index_col=None)[0])\n",
    "    results_as_html = summary.tables[1].as_html()\n",
    "    dfs.append(pd.read_html(results_as_html, index_col=None)[0])\n",
    "    summary = pd.concat(dfs, ignore_index=True)\n",
    "    R_square = float(summary.loc[0,3])\n",
    "    R = np.sqrt(R_square)\n",
    "    n,b,w = summary.loc[[5,10,11],1].values.astype(float)\n",
    "    \n",
    "    from scipy.stats import pearsonr\n",
    "    X_ = pearsonr(np.array(df[x]), np.array(df[y]))\n",
    "    print(\"X_------\", X_)\n",
    "\n",
    "    MAE = mean_absolute_error (df[x], df[y])\n",
    "    perc95_calib = np.percentile(abs(df[x]-df[y]),95)*2\n",
    "    \n",
    "    plt.figure(figsize=(10.0,8.5))\n",
    "    plt.title(name + model_name +  f\"\\n R: {round(R,3)} - MAE: {round(MAE,2)} - 95th percentile: {round(perc95_calib,2)}\", fontsize=16)#  R_Square: {round(R_square,3)}\") # \\n slope: {round(w,3)} intercept: {round(b,3)} samples: {n}\")\n",
    "    plt.scatter(df[y],df[x],s=1,alpha=0.6, color=\"tab:blue\")\n",
    "    plt.ylabel(\"Observed retention time\", fontsize=16)\n",
    "    plt.xlabel(\"Predicted retention time\", fontsize=16) \n",
    "    plt.ylim([0, 10000])\n",
    "    plt.xlim([0, 10000])\n",
    "    plt.savefig(name+ model_name +\".pdf\")\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        dict(\n",
    "            MAE=[MAE],perc95_calib=[perc95_calib], R_square=[R_square],R=[R],\n",
    "            slope=[w],intercept=[b],test_num=[n]\n",
    "        )\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Results (model, cal_df, data, name, model_name):\n",
    "    model.calibrate_preds(seq_df=cal_df)\n",
    "    preds_new = model.make_preds(seq_df=data, calibrate=True)\n",
    "    data['predicted_rt'] = preds_new\n",
    "    n = name\n",
    "    result_df = evaluate_linear_regression_plot_(data,\"tr\", \"predicted_rt\", n, model_name)\n",
    "    print(result_df)\n",
    "    data.to_csv(name + model_name+'.csv')\n",
    "    print(\"File saved at: \", name + model_name+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking predictions of test dataset from base model\n",
    "Train_UV= pd.read_csv(\"/home/ubuntu/NuXL_rescore/Deeplc_retrain/Train_RNA_UV.csv\")\n",
    "Test_UV = pd.read_csv(\"/home/ubuntu/NuXL_rescore/Deeplc_retrain/Test_RNA_UV.csv\") \n",
    "\n",
    "_ = tf.Variable([1])\n",
    "context._context = None\n",
    "context._create_context()\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1) \n",
    "\n",
    "dlc = DeepLC(\n",
    "        path_model=[\n",
    "                base_model +\"/full_hc_train_1fd8363d9af9dcad3be7553c39396960.hdf5\",\n",
    "                base_model +\"/full_hc_train_8c22d89667368f2f02ad996469ba157e.hdf5\",\n",
    "                base_model +\"/full_hc_train_cb975cfdd4105f97efa0b3afffe075cc.hdf5\"\n",
    "        ],\n",
    "        batch_num=1024000,\n",
    "        pygam_calibration=True,\n",
    "        f_extractor = features\n",
    ")\n",
    "\n",
    "model_Results(dlc, Train_UV, Test_UV, \"UV \", \"DeepLC (base model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking predictions of test dataset from generic model\n",
    "generic_model = \"/home/ubuntu/NuXL_rescore/RT_deeplc_model/generic_model\"\n",
    "\n",
    "_ = tf.Variable([1])\n",
    "context._context = None\n",
    "context._create_context()\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1) \n",
    "\n",
    "dlc = DeepLC(\n",
    "        path_model=[\n",
    "                generic_model + \"/full_hc_Train_RNA_All_1fd8363d9af9dcad3be7553c39396960.hdf5\",\n",
    "                generic_model + \"/full_hc_Train_RNA_All_8c22d89667368f2f02ad996469ba157e.hdf5\",\n",
    "                generic_model + \"/full_hc_Train_RNA_All_cb975cfdd4105f97efa0b3afffe075cc.hdf5\"\n",
    "        ],\n",
    "        batch_num=1024000,\n",
    "        pygam_calibration=True,\n",
    "        f_extractor = features\n",
    ")\n",
    "\n",
    "model_Results(dlc, Train_UV, Test_UV, \"UV \", \"DeepLC (generic model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training_Graph\n",
    "specific_model = \"/home/ubuntu/NuXL_rescore/RT_deeplc_model/specific_model\"\n",
    "\n",
    "_ = tf.Variable([1])\n",
    "context._context = None\n",
    "context._create_context()\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1) \n",
    "\n",
    "dlc = DeepLC(\n",
    "        path_model=[\n",
    "                specific_model + \"/full_hc_Train_RNA_UV_1fd8363d9af9dcad3be7553c39396960.hdf5\",\n",
    "                specific_model + \"/full_hc_Train_RNA_UV_8c22d89667368f2f02ad996469ba157e.hdf5\",\n",
    "                specific_model + \"/full_hc_Train_RNA_UV_cb975cfdd4105f97efa0b3afffe075cc.hdf5\"\n",
    "        ],\n",
    "        batch_num=1024000,\n",
    "        pygam_calibration=True,\n",
    "        f_extractor = features\n",
    ")\n",
    "\n",
    "model_Results(dlc, Train_UV, Test_UV, \"UV \", \"DeepLC (specific model)\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 20:29:25.225690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-11 20:29:25.227190: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-11 20:29:25.734426: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-11 20:29:25.735899: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 834ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pygam/utils.py:113: UserWarning: Expected 2D input data array, but found 1D. Expanding to 2D.\n",
      "  warnings.warn(msg)\n",
      "/home/ubuntu/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pygam/utils.py:78: UserWarning: Could not import Scikit-Sparse or Suite-Sparse.\n",
      "This will slow down optimization for models with monotonicity/convexity penalties and many splines.\n",
      "See installation instructions for installing Scikit-Sparse and Suite-Sparse via Conda.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 785ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pygam/utils.py:113: UserWarning: Expected 2D input data array, but found 1D. Expanding to 2D.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 859ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pygam/utils.py:113: UserWarning: Expected 2D input data array, but found 1D. Expanding to 2D.\n",
      "  warnings.warn(msg)\n",
      "/home/ubuntu/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pygam/utils.py:78: UserWarning: Could not import Scikit-Sparse or Suite-Sparse.\n",
      "This will slow down optimization for models with monotonicity/convexity penalties and many splines.\n",
      "See installation instructions for installing Scikit-Sparse and Suite-Sparse via Conda.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 873ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pygam/utils.py:113: UserWarning: Expected 2D input data array, but found 1D. Expanding to 2D.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fecb11c3670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 897ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pygam/utils.py:113: UserWarning: Expected 2D input data array, but found 1D. Expanding to 2D.\n",
      "  warnings.warn(msg)\n",
      "/home/ubuntu/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pygam/utils.py:78: UserWarning: Could not import Scikit-Sparse or Suite-Sparse.\n",
      "This will slow down optimization for models with monotonicity/convexity penalties and many splines.\n",
      "See installation instructions for installing Scikit-Sparse and Suite-Sparse via Conda.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fecb116cb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 873ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pygam/utils.py:113: UserWarning: Expected 2D input data array, but found 1D. Expanding to 2D.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 890ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pygam/utils.py:113: UserWarning: Expected 2D input data array, but found 1D. Expanding to 2D.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 965ms/step\n",
      "1/1 [==============================] - 1s 993ms/step\n",
      "X_------ PearsonRResult(statistic=0.6508709990903075, pvalue=0.0)\n",
      "           MAE  perc95_calib  R_square         R   slope  intercept  test_num\n",
      "0  1591.304037   6584.930202     0.424  0.651153  0.5762   2069.556    4367.0\n",
      "File saved at:  UV DeepLC (specific model) All Test data.csv\n"
     ]
    }
   ],
   "source": [
    "#Taking predictions from specific model on all test data\n",
    "specific_model = \"/home/ubuntu/NuXL_rescore/RT_deeplc_model/specific_model\"\n",
    "Train_UV= pd.read_csv(\"/home/ubuntu/NuXL_rescore/Deeplc_retrain/Train_RNA_UV.csv\")\n",
    "Test_All = pd.read_csv(\"/home/ubuntu/NuXL_rescore/Deeplc_retrain/Test_RNA_All.csv\")\n",
    "\n",
    "_ = tf.Variable([1]) \n",
    "context._context = None\n",
    "context._create_context()\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1) \n",
    "\n",
    "dlc = DeepLC(\n",
    "        path_model=[ \n",
    "                specific_model + \"/full_hc_Train_RNA_UV_1fd8363d9af9dcad3be7553c39396960.hdf5\",\n",
    "                specific_model + \"/full_hc_Train_RNA_UV_8c22d89667368f2f02ad996469ba157e.hdf5\",\n",
    "                specific_model + \"/full_hc_Train_RNA_UV_cb975cfdd4105f97efa0b3afffe075cc.hdf5\"\n",
    "        ],\n",
    "        batch_num=1024000,\n",
    "        pygam_calibration=True,\n",
    "        f_extractor = features\n",
    ")\n",
    "\n",
    "model_Results(dlc, Train_UV, Test_All, \"UV \", \"DeepLC (specific model) All Test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyopenms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1559363c6de5cf29960ea6f309a68e6370cc19d0a986c51230a800d5ddb281b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
